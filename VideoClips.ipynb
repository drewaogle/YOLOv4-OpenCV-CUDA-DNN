{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444a543-c419-4d24-8db4-1fea7ccdc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aperturedb tqdm\n",
    "from aperturedb import Utils\n",
    "c = Utils.create_connector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2a976-8ec0-4e99-a18b-85a1cc454bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Utils.Utils(c)\n",
    "u.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053c29f-bbaa-43f3-82e1-bfe103f72579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we retrieve the items we are working with:\n",
    "# Retrieve the YOLO4 interface\n",
    "!rm -f yolo4.py\n",
    "!wget https://raw.githubusercontent.com/drewaogle/YOLOv4-OpenCV-CUDA-DNN/refs/heads/main/yolo4.py\n",
    "# Retreive video\n",
    "!wget https://aperturedata-public.s3.us-west-2.amazonaws.com/aperturedb_applications/norman.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda14d1-dc17-48da-af51-bdeb8d6e468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from importlib import reload\n",
    "import yolo4\n",
    "reload(yolo4)\n",
    "from yolo4 import RemoteYOLOv4\n",
    "class DetectorOptions:\n",
    "    image='' # path for images\n",
    "    stream='' # path for stream\n",
    "    cfg=\"models/yolov4.cfg\" # path to config\n",
    "    weights=\"models/yolov4.weights\" # path to weights\n",
    "    namesfile=\"models/coco.names\" # path for output to name mapping\n",
    "    input_size=416\n",
    "    use_gpu=False # use GPU or not\n",
    "    outdir=\"output/norman\"\n",
    "    no_squash_detections=True # if detections exist, don't rerun.\n",
    "    def __init__(self, image='',stream=''):\n",
    "        self.image = image\n",
    "        self.stream=stream # 'webcam' to open webcam w/ OpenCV\n",
    "\n",
    "# now we pull data\n",
    "dopts = DetectorOptions( stream=\"norman.mp4\")\n",
    "yolo = RemoteYOLOv4.__new__(RemoteYOLOv4)\n",
    "yolo.__init__(dopts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3053bdb-a78a-4a8e-a454-2507a1477eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let't check detections\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"output/norman/detections.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503ff66-92c7-46a6-9dfb-9b55882c79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fist we'll define the options we're going to use.\n",
    "class ClipOptions:\n",
    "    offset_frame=0 # starting offset in frames\n",
    "    end_frame=-1 # ending offset in frames\n",
    "    initconf=50 # minimun confidence to start ( 0-100 )\n",
    "    initlen=5 # minimum detection duration in frames to start a clip\n",
    "    dropconf=25 # confidence to end a frame (0 -100 )\n",
    "    droplen=5 # number of detection missed frames to end a clip\n",
    "    detections=\"output/noman/detections.csv\" # path to output detections\n",
    "    verbose=False # lots of info\n",
    "    flush=False # remove old uuids\n",
    "    nosave=False # dont add data to db\n",
    "    label=\"\" # label for video\n",
    "    def __init__(self,video):\n",
    "        self.video=video # video file to add\n",
    "\n",
    "opts = ClipOptions( \"norman.mp4\" )\n",
    "opts.label=\"Norman_Bike\"\n",
    "opts.initconf=45\n",
    "opts.initlen=3\n",
    "opts.dropconf=20\n",
    "opts.droplen=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce21ed8-93bb-4d4f-8962-3dc77ce947f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare dataframe for work; add columns and trim frames we don't want.\n",
    "def preprocess(df, args ):\n",
    "   processed = df\n",
    "   processed.columns = [\"frame\",\"label\",\"confidence\",\"left\",\"top\",\"width\",\"height\" ]\n",
    "   processed.drop(processed[processed.frame < args.offset_frame].index, inplace=True)\n",
    "   if args.end_frame > -1:\n",
    "      processed.drop(processed[processed.frame > args.end_frame].index,inplace=True)\n",
    "   return processed\n",
    "\n",
    "norman_detects = preprocess( df, opts )\n",
    "print(norman_detects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580724fa-493f-429a-9504-140d412cf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a frame by hand here.\n",
    "from IPython.display import display as ds\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def display_image_and_bb( num, df ):\n",
    "                    \n",
    "    cv_image = cv2.imread( f\"output/norman/video{num}.jpg\")\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    counter = 0\n",
    "    for id,coords in df[df[\"frame\"] == num].iterrows():\n",
    "        left   = coords[\"left\"]\n",
    "        top    = coords[\"top\"]\n",
    "        right  = coords[\"left\"] + coords[\"width\"]\n",
    "        bottom = coords[\"top\"] + coords[\"height\"]\n",
    "        cv2.rectangle(cv_image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(cv_image, coords[\"label\"], (left, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        counter += 1\n",
    "\n",
    "    cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "    ds(Image.fromarray(cv_image_rgb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98818068-81a0-4bc9-979e-44fc844ed36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_bb( 150, norman_detects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6815a-07a8-4fa7-bc42-4f7b2cc89ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple Clip class for data storage\n",
    "class Clip:\n",
    "    def __init__(self, label, start,conf):\n",
    "        self.label = label\n",
    "        self.start_frame = start\n",
    "        self.total_frames = 0 # don't include start in total.\n",
    "        self.missed_frames = 0\n",
    "        self.max_confidence = conf\n",
    "        self.min_confidence = conf\n",
    "    def is_active( self, current_frame, drop_len ):\n",
    "        last_seen = self.start_frame + self.total_frames\n",
    "        # drop_len is the number of frame that can be missed and label is \"active\"\n",
    "        # drop_len of 1 means active continues if unseen in previous frame.\n",
    "        return last_seen + drop_len > current_frame\n",
    "    def __str__(self):\n",
    "        return f\"(Clip [{self.label}] @ {self.start_frame} + {self.total_frames}\"\n",
    "    def __repr__(self):\n",
    "        return f\"C[{self.label} @ {self.start_frame} + {self.total_frames}]\"\n",
    "    def as_finished(self):\n",
    "        return f\"{self.label}_{self.start_frame+self.total_frames}\"\n",
    "    def add_confidence(self,new_confidence):\n",
    "        self.max_confidence = max(self.max_confidence,new_confidence)\n",
    "        self.min_confidence = min(self.min_confidence,new_confidence)\n",
    "        self.total_frames = self.total_frames + 1 + self.missed_frames\n",
    "        # when a frame is a hit, we add the missed frames to what is considered the total length.\n",
    "        self.missed_frames = 0 \n",
    "    # frames where confidence was below threshold but kept to avoid drop out.\n",
    "    def add_missed(self,missed_confidence):\n",
    "        self.missed_frames = self.missed_frames + 1\n",
    "\n",
    "class ClipStorage:\n",
    "    def __init__(self):\n",
    "        self.active = {} # clips that have been seen, but not passed initializition count ( suppressed mis-identification )\n",
    "        self.registered = {} # clips that are 'valid', and currently \"seent\"\n",
    "        self.finished = {} # clips that were valid, but dropped off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e8318-bd6f-4520-88dd-f0b801f1a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process events which trigger on new frame.\n",
    "def process_new_frame( verbose, drop_len, cur_frame, last_frame, storage): \n",
    "           # drop any which werent active last frame\n",
    "           new_active = {}\n",
    "           new_registered = {}\n",
    "           for clip in storage.active.values():\n",
    "               if not clip.is_active( cur_frame, drop_len ):\n",
    "                   if verbose:\n",
    "                       print(f'At frame {cur_frame}, Dropped {clip}') #{old_label} ( last active {last_active} )')                   \n",
    "               else:   \n",
    "                   if verbose:\n",
    "                       print(f\"At frame {cur_frame}, kept {clip}\")\n",
    "                   new_active[clip.label] = clip\n",
    "           for clip in storage.registered.values():\n",
    "               if not clip.is_active( cur_frame, drop_len ): #cur_frame != last_active +1:\n",
    "                   if verbose:\n",
    "                       print(f'At frame {cur_frame}, Retired {clip}') #{old_label} frame duration: {total_active}, started {start_frame}')\n",
    "                   storage.finished[ clip.as_finished() ] = clip\n",
    "               else:\n",
    "                   new_registered[clip.label] = clip\n",
    "           if verbose:\n",
    "               print(f\"Active dict: {storage.active}\")\n",
    "           storage.registered = new_registered\n",
    "           storage.active = new_active   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ae077-3233-485a-b5df-7ffabd6cd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a row in the detections\n",
    "# YOLOv4 can detect mutitple objects in a frame - this is a single detection in a given frame.\n",
    "def process_row(verbose, initconf, initlen, dropconf, cur_frame, label, label_confidence, storage):\n",
    "       if label in storage.active.keys():\n",
    "           clip = storage.active[label]\n",
    "           if label_confidence * 100 > initconf:\n",
    "               clip.add_confidence(label_confidence)\n",
    "               # total frames doesn't include first frame, so add 1.\n",
    "               if clip.total_frames +1 >= initlen: \n",
    "                   if verbose:\n",
    "                       print(f\"At {cur_frame}, moved {clip} to registered\")\n",
    "                   storage.registered[label] = clip\n",
    "                   del storage.active[label]\n",
    "               else:\n",
    "                   if verbose:\n",
    "                       print(f\"At frame {cur_frame}, saw {clip}\")\n",
    "           else:   \n",
    "               if verbose:\n",
    "                   print(f\"{clip} seen at frame {cur_frame}, but confidence [ {label_confidence*100} < { initconf }]\" )\n",
    "       elif label in storage.registered.keys():\n",
    "           clip = storage.registered[label]\n",
    "           # if above confidence for dropping, consider a new registered frame\n",
    "           if label_confidence * 100 > dropconf:\n",
    "                # allows frame to miss one and restart; duration calculated from start to current.\n",
    "                clip.add_confidence(label_confidence)\n",
    "           else:\n",
    "               clip.add_missed(label_confidence)\n",
    "       else:    \n",
    "           # if label not in active list, nor registered.\n",
    "           if label_confidence * 100 > initconf:\n",
    "               clip = Clip( label, cur_frame, label_confidence )\n",
    "               if verbose: \n",
    "                   print(f\"* Added {clip} to actived\")\n",
    "               storage.active[label] = clip\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b192263-c3d8-4de3-87d2-d3ec26e3ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop over a frame.\n",
    "def process(args,pf):\n",
    "    args.verbose = True\n",
    "    clip_store = ClipStorage()\n",
    "    last_frame =0\n",
    "    cur_frame = 0\n",
    "    for idx,row in pf.iterrows():\n",
    "        cur_frame = row['frame']\n",
    "        label = row['label']\n",
    "        if cur_frame > 155:\n",
    "            break\n",
    "        if cur_frame != last_frame:\n",
    "           if args.verbose:\n",
    "               print(f\"Processing switch from {last_frame} to {cur_frame}\")\n",
    "           process_new_frame(args.verbose,args.droplen, cur_frame, last_frame,clip_store)\n",
    "\n",
    "        # all old active and registered are dropped prior to this.\n",
    "        process_row(args.verbose, args.initconf, args.initlen, args.dropconf,cur_frame,label,row['confidence'],clip_store)\n",
    "\n",
    "        last_frame = cur_frame\n",
    "    return registered,finished\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03f241-edad-4817-b07f-75de6565960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "norman_registered,norman_finished = process(opts,norman_detects)\n",
    "print(norman_registered)\n",
    "print(norman_finished)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
